diff --git netcdf_output.py netcdf_output.py
--- netcdf_output.py
+++ netcdf_output.py
@@ -13,6 +13,21 @@
 import hyp3_autorift
 
 
+def get_satellite_attribte(info):
+    mission_mapping = {
+        'L': 'Landsat',
+        'S': 'Sentinel',
+    }
+
+    satellite_1 = f'{mission_mapping[info["mission_img1"]]} {info["satellite_img1"]}'
+    satellite_2 = f'{mission_mapping[info["mission_img2"]]} {info["satellite_img2"]}'
+
+    if satellite_1 != satellite_2:
+        return f'{satellite_1} and {satellite_2}'
+
+    return satellite_1
+
+
 def v_error_cal(vx_error, vy_error):
     vx = np.random.normal(0, vx_error, 1000000)
     vy = np.random.normal(0, vy_error, 1000000)
@@ -362,12 +377,13 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
     # First set global attributes that GDAL uses when it reads netCFDF files
     nc_outfile.setncattr('GDAL_AREA_OR_POINT', 'Area')
-    nc_outfile.setncattr('Conventions', 'CF-1.6')
+    nc_outfile.setncattr('Conventions', 'CF-1.8')
     nc_outfile.setncattr('date_created', datetime.datetime.now().strftime("%d-%b-%Y %H:%M:%S"))
     nc_outfile.setncattr('title', title)
     nc_outfile.setncattr('autoRIFT_software_version', IMG_INFO_DICT["autoRIFT_software_version"])
     nc_outfile.setncattr('autoRIFT_parameter_file', parameter_file)
     nc_outfile.setncattr('scene_pair_type', pair_type)
+    nc_outfile.setncattr('satellite', get_satellite_attribte(IMG_INFO_DICT))
     nc_outfile.setncattr('motion_detection_method', detection_method)
     nc_outfile.setncattr('motion_coordinates', coordinates)
     nc_outfile.setncattr('author', author)
@@ -377,6 +393,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
 
     var = nc_outfile.createVariable('img_pair_info', 'U1', (), fill_value=None)
+    var.setncattr('standard_name', 'image_pair_information')
     for key in IMG_INFO_DICT:
         if key == 'autoRIFT_software_version':
             continue
@@ -398,9 +415,6 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
     var.setncattr('standard_name', 'projection_x_coordinate')
     var.setncattr('description', 'x coordinate of projection')
     var.setncattr('units', 'm')
-    # var.setncattr('scene_pair_type', pair_type)
-    # var.setncattr('motion_detection_method', detection_method)
-    # var.setncattr('motion_coordinates', coordinates)
     var[:] = x
 
 
@@ -408,9 +422,6 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
     var.setncattr('standard_name', 'projection_y_coordinate')
     var.setncattr('description', 'y coordinate of projection')
     var.setncattr('units', 'm')
-    # var.setncattr('scene_pair_type', pair_type)
-    # var.setncattr('motion_detection_method', detection_method)
-    # var.setncattr('motion_coordinates', coordinates)
     var[:] = y
 
 
@@ -423,13 +434,12 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('false_northing', srs.GetProjParm('false_northing'))
         var.setncattr('latitude_of_projection_origin', np.sign(srs.GetProjParm('latitude_of_origin'))*90.0)  # could hardcode this to be -90 for landsat - just making it more general, maybe...
         var.setncattr('latitude_of_origin', srs.GetProjParm('latitude_of_origin'))
-        # var.setncattr('longitude_of_prime_meridian', float(srs.GetAttrValue('GEOGCS|PRIMEM', 1)))
         var.setncattr('semi_major_axis', float(srs.GetAttrValue('GEOGCS|SPHEROID', 1)))
-        # var.setncattr('semi_minor_axis', float(6356.752))
         var.setncattr('scale_factor_at_projection_origin', 1)
         var.setncattr('inverse_flattening', float(srs.GetAttrValue('GEOGCS|SPHEROID', 2)))
         var.setncattr('spatial_ref', srs.ExportToWkt())
-        var.setncattr('spatial_proj4', srs.ExportToProj4())
+        var.setncattr('crs_wkt', srs.ExportToWkt())
+        var.setncattr('proj4text', srs.ExportToProj4())
         var.setncattr('spatial_epsg', epsg)
         var.setncattr('GeoTransform', ' '.join(str(x) for x in tran))  # note this has pixel size in it - set  explicitly above
 
@@ -437,18 +447,16 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('grid_mapping_name', 'universal_transverse_mercator')
         zone = epsg - np.floor(epsg/100)*100
         var.setncattr('utm_zone_number', zone)
-        var.setncattr('CoordinateTransformType', 'Projection')
-        var.setncattr('CoordinateAxisTypes', 'GeoX GeoY')
-        # var.setncattr('longitude_of_central_meridian', srs.GetProjParm('central_meridian'))
-        # var.setncattr('false_easting', srs.GetProjParm('false_easting'))
-        # var.setncattr('false_northing', srs.GetProjParm('false_northing'))
-        # var.setncattr('latitude_of_projection_origin', srs.GetProjParm('latitude_of_origin'))
-        # var.setncattr('scale_factor_at_central_meridian', srs.GetProjParm('scale_factor'))
-        # var.setncattr('longitude_of_prime_meridian', float(srs.GetAttrValue('GEOGCS|PRIMEM', 1)))
+        var.setncattr('longitude_of_central_meridian', srs.GetProjParm('central_meridian'))
+        var.setncattr('false_easting', srs.GetProjParm('false_easting'))
+        var.setncattr('false_northing', srs.GetProjParm('false_northing'))
+        var.setncattr('latitude_of_projection_origin', srs.GetProjParm('latitude_of_origin'))
         var.setncattr('semi_major_axis', float(srs.GetAttrValue('GEOGCS|SPHEROID', 1)))
+        var.setncattr('scale_factor_at_central_meridian', srs.GetProjParm('scale_factor'))
         var.setncattr('inverse_flattening', float(srs.GetAttrValue('GEOGCS|SPHEROID', 2)))
         var.setncattr('spatial_ref', srs.ExportToWkt())
-        var.setncattr('spatial_proj4', srs.ExportToProj4())
+        var.setncattr('crs_wkt', srs.ExportToWkt())
+        var.setncattr('proj4text', srs.ExportToProj4())
         var.setncattr('spatial_epsg', epsg)
         var.setncattr('GeoTransform', ' '.join(str(x) for x in tran))  # note this has pixel size in it - set  explicitly above
 
@@ -458,12 +466,12 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
     var = nc_outfile.createVariable('vx', np.dtype('int16'), ('y', 'x'), fill_value=NoDataValue,
                                     zlib=True, complevel=2, shuffle=True, chunksizes=ChunkSize)
-    var.setncattr('standard_name', 'x_velocity')
+    var.setncattr('standard_name', 'land_ice_surface_x_velocity')
     if pair_type == 'radar':
         var.setncattr('description', 'velocity component in x direction from radar range and azimuth measurements')
     else:
         var.setncattr('description', 'velocity component in x direction')
-    var.setncattr('units', 'm/y')
+    var.setncattr('units', 'meter/year')
     var.setncattr('grid_mapping', mapping_var_name)
 
     if stable_count != 0:
@@ -497,11 +505,11 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
                                        'correction as indicated in "stable_shift_flag"')
 
     if stable_count != 0:
-        var.setncattr('error_mask', int(round(vx_error_mask*10))/10)
+        var.setncattr('error_stationary', int(round(vx_error_mask*10))/10)
     else:
-        var.setncattr('error_mask', np.nan)
-    var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing '
-                                            'surfaces with velocity < 15 m/yr identified from an external mask')
+        var.setncattr('error_stationary', np.nan)
+    var.setncattr('error_stationary_description', 'RMSE over stable surfaces, stationary or slow-flowing '
+                                            'surfaces with velocity < 15 meter/year identified from an external mask')
 
     var.setncattr('error_modeled', int(round(vx_error_mod*10))/10)
     var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -521,15 +529,15 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
     var.setncattr('stable_shift_flag', stable_shift_applied)
     var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
                                                    '1 = correction from overlapping stable surface mask (stationary '
-                                                   'or slow-flowing surfaces with velocity < 15 m/yr)(top priority); '
+                                                   'or slow-flowing surfaces with velocity < 15 meter/year)(top priority); '
                                                    '2 = correction from slowest 25% of overlapping velocities '
                                                    '(second priority)')
 
     if stable_count != 0:
-        var.setncattr('stable_shift_mask', int(round(vx_mean_shift*10))/10)
+        var.setncattr('stable_shift_stationary', int(round(vx_mean_shift*10))/10)
     else:
-        var.setncattr('stable_shift_mask', np.nan)
-    var.setncattr('stable_count_mask', stable_count)
+        var.setncattr('stable_shift_stationary', np.nan)
+    var.setncattr('stable_count_stationary', stable_count)
 
     if stable_count1 != 0:
         var.setncattr('stable_shift_slow', int(round(vx_mean_shift1*10))/10)
@@ -544,12 +552,12 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
     var = nc_outfile.createVariable('vy', np.dtype('int16'), ('y', 'x'), fill_value=NoDataValue,
                                     zlib=True, complevel=2, shuffle=True, chunksizes=ChunkSize)
-    var.setncattr('standard_name', 'y_velocity')
+    var.setncattr('standard_name', 'land_ice_surface_y_velocity')
     if pair_type == 'radar':
         var.setncattr('description', 'velocity component in y direction from radar range and azimuth measurements')
     else:
         var.setncattr('description', 'velocity component in y direction')
-    var.setncattr('units', 'm/y')
+    var.setncattr('units', 'meter/year')
     var.setncattr('grid_mapping', mapping_var_name)
 
     if stable_count != 0:
@@ -582,11 +590,11 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
                                        'in "stable_shift_flag"')
 
     if stable_count != 0:
-        var.setncattr('error_mask', int(round(vy_error_mask*10))/10)
+        var.setncattr('error_stationary', int(round(vy_error_mask*10))/10)
     else:
-        var.setncattr('error_mask', np.nan)
-    var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces '
-                                            'with velocity < 15 m/yr identified from an external mask')
+        var.setncattr('error_stationary', np.nan)
+    var.setncattr('error_stationary_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces '
+                                            'with velocity < 15 meter/year identified from an external mask')
 
     var.setncattr('error_modeled', int(round(vy_error_mod * 10)) / 10)
     var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -607,15 +615,15 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
     var.setncattr('stable_shift_flag', stable_shift_applied)
     var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
                                                    '1 = correction from overlapping stable surface mask (stationary '
-                                                   'or slow-flowing surfaces with velocity < 15 m/yr)(top priority); '
+                                                   'or slow-flowing surfaces with velocity < 15 meter/year)(top priority); '
                                                    '2 = correction from slowest 25% of overlapping velocities '
                                                    '(second priority)')
 
     if stable_count != 0:
-        var.setncattr('stable_shift_mask', int(round(vy_mean_shift*10))/10)
+        var.setncattr('stable_shift_stationary', int(round(vy_mean_shift*10))/10)
     else:
-        var.setncattr('stable_shift_mask', np.nan)
-    var.setncattr('stable_count_mask', stable_count)
+        var.setncattr('stable_shift_stationary', np.nan)
+        var.setncattr('stable_count_stationary', stable_count)
 
     if stable_count1 != 0:
         var.setncattr('stable_shift_slow', int(round(vy_mean_shift1*10))/10)
@@ -630,12 +638,12 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
     var = nc_outfile.createVariable('v', np.dtype('int16'), ('y', 'x'), fill_value=NoDataValue,
                                     zlib=True, complevel=2, shuffle=True, chunksizes=ChunkSize)
-    var.setncattr('standard_name', 'velocity')
+    var.setncattr('standard_name', 'land_ice_surface_velocity')
     if pair_type == 'radar':
         var.setncattr('description', 'velocity magnitude from radar range and azimuth measurements')
     else:
         var.setncattr('description', 'velocity magnitude')
-    var.setncattr('units', 'm/y')
+    var.setncattr('units', 'meter/year')
     var.setncattr('grid_mapping', mapping_var_name)
 
     V[noDataMask] = NoDataValue
@@ -650,7 +658,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('description', 'velocity magnitude error from radar range and azimuth measurements')
     else:
         var.setncattr('description', 'velocity magnitude error')
-    var.setncattr('units', 'm/y')
+    var.setncattr('units', 'meter/year')
     var.setncattr('grid_mapping', mapping_var_name)
 
     v_error = v_error_cal(vx_error, vy_error)
@@ -667,7 +675,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
 
         var.setncattr('standard_name', 'range_velocity')
         var.setncattr('description', 'velocity in radar range direction')
-        var.setncattr('units', 'm/y')
+        var.setncattr('units', 'meter/year')
         var.setncattr('grid_mapping', mapping_var_name)
 
         if stable_count != 0:
@@ -702,7 +710,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         else:
             var.setncattr('error_mask', np.nan)
         var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing '
-                                                'surfaces with velocity < 15 m/yr identified from an external mask')
+                                                'surfaces with velocity < 15 meter/year identified from an external mask')
 
         var.setncattr('error_modeled', int(round(vr_error_mod*10))/10)
         var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -722,15 +730,15 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('stable_shift_flag', stable_shift_applied)
         var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
                                                        '1 = correction from overlapping stable surface mask '
-                                                       '(stationary or slow-flowing surfaces with velocity < 15 m/yr)'
+                                                       '(stationary or slow-flowing surfaces with velocity < 15 meter/year)'
                                                        '(top priority); 2 = correction from slowest 25% of overlapping '
                                                        'velocities (second priority)')
 
         if stable_count != 0:
-            var.setncattr('stable_shift_mask', int(round(vr_mean_shift*10))/10)
+            var.setncattr('stable_shift_stationary', int(round(vr_mean_shift*10))/10)
         else:
-            var.setncattr('stable_shift_mask', np.nan)
-        var.setncattr('stable_count_mask', stable_count)
+            var.setncattr('stable_shift_stationary', np.nan)
+        var.setncattr('stable_count_stationary', stable_count)
 
         if stable_count1 != 0:
             var.setncattr('stable_shift_slow', int(round(vr_mean_shift1*10))/10)
@@ -747,7 +755,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
                                         zlib=True, complevel=2, shuffle=True, chunksizes=ChunkSize)
         var.setncattr('standard_name', 'azimuth_velocity')
         var.setncattr('description', 'velocity in radar azimuth direction')
-        var.setncattr('units', 'm/y')
+        var.setncattr('units', 'meter/year')
         var.setncattr('grid_mapping', mapping_var_name)
 
         if stable_count != 0:
@@ -781,7 +789,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
             var.setncattr('error_mask', int(round(va_error_mask*10))/10)
         else:
             var.setncattr('error_mask', np.nan)
-        var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces with velocity < 15 m/yr identified from an external mask')
+        var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces with velocity < 15 meter/year identified from an external mask')
 
         var.setncattr('error_modeled', int(round(va_error_mod*10))/10)
         var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -801,7 +809,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('stable_shift_flag', stable_shift_applied)
         var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
                                                        '1 = correction from overlapping stable surface mask '
-                                                       '(stationary or slow-flowing surfaces with velocity < 15 m/yr)'
+                                                       '(stationary or slow-flowing surfaces with velocity < 15 meter/yearr)'
                                                        '(top priority); 2 = correction from slowest 25% of overlapping '
                                                        'velocities (second priority)')
 
@@ -912,7 +920,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('description', 'x-direction velocity determined by projecting radar range measurements '
         #                              'onto an a priori flow vector. Where projected errors are larger than those '
         #                              'determined from range and azimuth measurements, unprojected vx estimates are used')
-        # var.setncattr('units', 'm/y')
+        # var.setncattr('units', 'meter/year')
         # var.setncattr('grid_mapping', mapping_var_name)
         #
         # if stable_count_p != 0:
@@ -945,7 +953,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # else:
         #     var.setncattr('error_mask', np.nan)
         # var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces '
-        #                                         'with velocity < 15 m/yr identified from an external mask')
+        #                                         'with velocity < 15 meter/year identified from an external mask')
         #
         # var.setncattr('error_modeled', int(round(vxp_error_mod * 10)) / 10)
         # var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -965,7 +973,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('stable_shift_flag', stable_shift_applied_p)
         # var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
         #                                                '1 = correction from overlapping stable surface mask '
-        #                                                '(stationary or slow-flowing surfaces with velocity < 15 m/yr)'
+        #                                                '(stationary or slow-flowing surfaces with velocity < 15 meter/year)'
         #                                                '(top priority); 2 = correction from slowest 25% of overlapping '
         #                                                'velocities (second priority)')
         #
@@ -992,7 +1000,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('description', 'y-direction velocity determined by projecting radar range measurements '
         #                              'onto an a priori flow vector. Where projected errors are larger than those '
         #                              'determined from range and azimuth measurements, unprojected vy estimates are used')
-        # var.setncattr('units', 'm/y')
+        # var.setncattr('units', 'meter/year')
         # var.setncattr('grid_mapping', mapping_var_name)
         #
         # if stable_count_p != 0:
@@ -1025,7 +1033,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # else:
         #     var.setncattr('error_mask', np.nan)
         # var.setncattr('error_mask_description', 'RMSE over stable surfaces, stationary or slow-flowing surfaces '
-        #                                         'with velocity < 15 m/yr identified from an external mask')
+        #                                         'with velocity < 15 meter/year identified from an external mask')
         #
         # var.setncattr('error_modeled', int(round(vyp_error_mod * 10)) / 10)
         # var.setncattr('error_modeled_description', '1-sigma error calculated using a modeled error-dt relationship')
@@ -1045,7 +1053,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('stable_shift_flag', stable_shift_applied_p)
         # var.setncattr('stable_shift_flag_description', 'flag for applying velocity bias correction: 0 = no correction; '
         #                                                '1 = correction from overlapping stable surface mask '
-        #                                                '(stationary or slow-flowing surfaces with velocity < 15 m/yr)'
+        #                                                '(stationary or slow-flowing surfaces with velocity < 15 meter/year)'
         #                                                '(top priority); 2 = correction from slowest 25% of overlapping '
         #                                                'velocities (second priority)')
         #
@@ -1072,7 +1080,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('description', 'velocity magnitude determined by projecting radar range measurements '
         #                              'onto an a priori flow vector. Where projected errors are larger than those '
         #                              'determined from range and azimuth measurements, unprojected v estimates are used')
-        # var.setncattr('units', 'm/y')
+        # var.setncattr('units', 'meter/year')
         # var.setncattr('grid_mapping', mapping_var_name)
         #
         # VP[noDataMask] = NoDataValue
@@ -1086,7 +1094,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         # var.setncattr('description', 'velocity magnitude error determined by projecting radar range measurements '
         #                              'onto an a priori flow vector. Where projected errors are larger than those '
         #                              'determined from range and azimuth measurements, unprojected v_error estimates are used')
-        # var.setncattr('units', 'm/y')
+        # var.setncattr('units', 'meter/year')
         # var.setncattr('grid_mapping', mapping_var_name)
         #
         # vp_error = v_error_cal(vxp_error, vyp_error)
@@ -1102,7 +1110,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('standard_name', 'conversion_matrix_element_11')
         var.setncattr('description', 'conversion matrix element (1st row, 1st column) that can be multiplied with vx '
                                      'to give range pixel displacement dr (see Eq. A18 in https://www.mdpi.com/2072-4292/13/4/749)')
-        var.setncattr('units', 'pixel/(m/y)')
+        var.setncattr('units', 'pixel/(meter/year)')
         var.setncattr('grid_mapping', mapping_var_name)
         var.setncattr('dr_to_vr_factor', dr_2_vr_factor)
         var.setncattr('dr_to_vr_factor_description', 'multiplicative factor that converts slant range '
@@ -1133,7 +1141,7 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
         var.setncattr('standard_name', 'conversion_matrix_element_12')
         var.setncattr('description', 'conversion matrix element (1st row, 2nd column) that can be multiplied with vy '
                                      'to give range pixel displacement dr (see Eq. A18 in https://www.mdpi.com/2072-4292/13/4/749)')
-        var.setncattr('units', 'pixel/(m/y)')
+        var.setncattr('units', 'pixel/(meter/year)')
         var.setncattr('grid_mapping', mapping_var_name)
 
         var.setncattr('dr_to_vr_factor', dr_2_vr_factor)
@@ -1201,8 +1209,9 @@ def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1
     var = nc_outfile.createVariable('interp_mask', np.dtype('uint8'), ('y', 'x'), fill_value=0,
                                     zlib=True, complevel=2, shuffle=True, chunksizes=ChunkSize)
     var.setncattr('standard_name', 'interpolated_value_mask')
-    var.setncattr('description', 'light interpolation mask')
-    var.setncattr('units', 'binary')
+    var.setncattr('description', 'true where values have been interpolated')
+    var.setncattr('flag_values', [np.uint8(0), np.uint8(1)])
+    var.setncattr('flag_meanings', 'measured, interpolated')
     var.setncattr('grid_mapping', mapping_var_name)
 
     # var[:] = np.flipud(vx_nomask).astype('float32')
diff --git testautoRIFT.py testautoRIFT.py
--- testautoRIFT.py
+++ testautoRIFT.py
@@ -854,7 +854,7 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
-                    coordinates = 'radar'
+                    coordinates = 'radar, map'
                     if np.sum(SEARCHLIMITX!=0)!=0:
                         roi_valid_percentage = int(round(np.sum(CHIPSIZEX!=0)/np.sum(SEARCHLIMITX!=0)*1000.0))/1000
                     else:
@@ -883,6 +883,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_filename[0:-4],
+                        'id_img2': slave_filename[0:-4],
                         'absolute_orbit_number_img1': master_split[7],
                         'absolute_orbit_number_img2': slave_split[7],
                         'acquisition_date_img1': master_dt,
@@ -980,6 +982,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_filename[0:-7],
+                        'id_img2': slave_filename[0:-7],
                         'acquisition_date_img1': master_dt,
                         'acquisition_date_img2': slave_dt,
                         'collection_category_img1': master_split[6],
@@ -1075,6 +1079,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_id,
+                        'id_img2': slave_id,
                         'acquisition_date_img1': master_dt,
                         'acquisition_date_img2': slave_dt,
                         'correction_level_img1': master_split[1][3:],
diff --git testautoRIFT_ISCE.py testautoRIFT_ISCE.py
--- testautoRIFT_ISCE.py
+++ testautoRIFT_ISCE.py
@@ -853,7 +853,7 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
-                    coordinates = 'radar'
+                    coordinates = 'radar, map'
                     if np.sum(SEARCHLIMITX!=0)!=0:
                         roi_valid_percentage = int(round(np.sum(CHIPSIZEX!=0)/np.sum(SEARCHLIMITX!=0)*1000.0))/1000
                     else:
@@ -882,6 +882,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_filename[0:-4],
+                        'id_img2': slave_filename[0:-4],
                         'absolute_orbit_number_img1': master_split[7],
                         'absolute_orbit_number_img2': slave_split[7],
                         'acquisition_date_img1': master_dt,
@@ -979,6 +981,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_filename[0:-7],
+                        'id_img2': slave_filename[0:-7],
                         'acquisition_date_img1': master_dt,
                         'acquisition_date_img2': slave_dt,
                         'collection_category_img1': master_split[6],
@@ -1074,6 +1078,8 @@ def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
                     IMG_INFO_DICT = {
+                        'id_img1': master_id,
+                        'id_img2': slave_id,
                         'acquisition_date_img1': master_dt,
                         'acquisition_date_img2': slave_dt,
                         'correction_level_img1': master_split[1][3:],
