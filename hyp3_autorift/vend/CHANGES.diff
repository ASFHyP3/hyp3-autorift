--- netcdf_output.py
+++ netcdf_output.py
@@ -4,38 +4,13 @@
 #Yang Lei, Jet Propulsion Laboratory
 #November 2017
 
-import xml.etree.ElementTree as ET
-#from numpy import *
 import numpy as np
-import scipy.io as sio
-##import commands
 import subprocess
 import os
-import time
-import argparse
-import pdb
-import os
-import isce
-import isceobj
-import shelve
-import string
-import sys
 import datetime
 import netCDF4
-from scipy import stats
 
-#def cmdLineParse():
-#    '''
-#    Command line parser.
-#    '''
-#    parser = argparse.ArgumentParser(description="Single-pair InSAR processing of Sentinel-1 data using ISCE modules")
-#
-#    return parser.parse_args()
-
-
-def runCmd(cmd):
-    out = subprocess.getoutput(cmd)
-    return out
+import hyp3_autorift
 
 def v_error_cal(vx_error, vy_error):
     vx = np.random.normal(0, vx_error, 1000000)
@@ -227,9 +202,11 @@
     return Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask
 
 
-def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1, SX, SY, offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref, DXref, DYref, rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type, detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied, dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector):
-    
-    
+def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1, SX, SY,
+                     offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
+                     DXref, DYref, rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
+                     detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
+                     dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector, parameter_file):
     vx_mean_shift = offset2vx_1 * dx_mean_shift + offset2vx_2 * dy_mean_shift
     temp = vx_mean_shift
     temp[np.logical_not(SSM)] = np.nan
@@ -414,6 +391,29 @@
 #    CHIPSIZEY = np.round(np.clip(CHIPSIZEY, 0, 65535)).astype(np.uint16)
 #    INTERPMASK = np.round(np.clip(INTERPMASK, 0, 255)).astype(np.uint8)
 
+    source = f'NASA MEaSUREs ITS_LIVE project. Processed by ASF DAAC HyP3 {datetime.datetime.now().year} using the ' \
+             f'{hyp3_autorift.__name__} plugin version {hyp3_autorift.__version__} running autoRIFT version ' \
+             f'{IMG_INFO_DICT["autoRIFT_software_version"]}'
+    if pair_type == 'radar':
+        isce_version = subprocess.check_output('conda list | grep isce | awk \'{print $2}\'', shell=True, text=True)
+        source += f' built with ISCE version {isce_version.strip()}'
+    if IMG_INFO_DICT['mission_img1'].startswith('S'):
+        source += f'. Contains modified Copernicus Sentinel data {IMG_INFO_DICT["date_center"][0:4]}, processed by ESA'
+    if IMG_INFO_DICT['mission_img1'].startswith('L'):
+        source += f'. Landsat-{IMG_INFO_DICT["satellite_img1"]:.0f} images courtesy of the U.S. Geological Survey'
+
+    references = 'When using this data, please acknowledge the source (see global source attribute) and cite:\n' \
+                 '* Gardner, A. S., Moholdt, G., Scambos, T., Fahnestock, M., Ligtenberg, S., van den Broeke, M.,\n' \
+                 '  and Nilsson, J., 2018. Increased West Antarctic and unchanged East Antarctic ice discharge over\n' \
+                 '  the last 7 years. The Cryosphere, 12, p.521. https://doi.org/10.5194/tc-12-521-2018\n' \
+                 '* Lei, Y., Gardner, A. and Agram, P., 2021. Autonomous Repeat Image Feature Tracking (autoRIFT)\n' \
+                 '  and Its Application for Tracking Ice Displacement. Remote Sensing, 13(4), p.749.\n' \
+                 '  https://doi.org/10.3390/rs13040749\n' \
+                 '\n' \
+                 'Additionally, DOI\'s are provided for the software used to generate this data:\n' \
+                 '* autoRIFT: https://doi.org/10.5281/zenodo.4025445\n' \
+                 '* HyP3 autoRIFT plugin: https://doi.org/10.5281/zenodo.4037016\n' \
+                 '* HyP3 processing environment: https://doi.org/10.5281/zenodo.3962581'
     
     tran = [tran[0] + tran[1]/2, tran[1], 0.0, tran[3] + tran[5]/2, 0.0, tran[5]]
     
@@ -426,35 +426,15 @@
     nc_outfile.setncattr('Conventions','CF-1.6')
     nc_outfile.setncattr('date_created',datetime.datetime.now().strftime("%d-%b-%Y %H:%M:%S"))
     nc_outfile.setncattr('title',title)
-    nc_outfile.setncattr('author',author)
-    nc_outfile.setncattr('institution',institution)
-#    nc_outfile.setncattr('Software',version)
+    nc_outfile.setncattr('autoRIFT_software_version', IMG_INFO_DICT["autoRIFT_software_version"])
+    nc_outfile.setncattr('autoRIFT_parameter_file', parameter_file)
     nc_outfile.setncattr('scene_pair_type',pair_type)
     nc_outfile.setncattr('motion_detection_method',detection_method)
     nc_outfile.setncattr('motion_coordinates',coordinates)
-
-    # if we were copying from an nc file, we would...
-    # for attr in vv_nc_basefile.ncattrs():
-    #     nc_outfile.setncattr(attr,vv_nc_basefile.getncattr(attr))
-    
-#    from topsApp import TopsInSAR
-#    insar = TopsInSAR(name="topsApp")
-#    insar.configure()
-#    master_filename = os.path.basename(insar.master.safe[0])
-#    slave_filename = os.path.basename(insar.slave.safe[0])
-
-#    import topsinsar_filename as tf
-#    master_filename, slave_filename = tf.loadXml()
-
-
-#    runCmd('topsinsar_filename.py')
-#    import scipy.io as sio
-#    conts = sio.loadmat('topsinsar_filename.mat')
-#    master_filename = conts['master_filename'][0]
-#    slave_filename = conts['slave_filename'][0]
-#    master_split = str.split(master_filename,'_')
-#    slave_split = str.split(slave_filename,'_')
-
+    nc_outfile.setncattr('author', author)
+    nc_outfile.setncattr('institution', institution)
+    nc_outfile.setncattr('source', source)
+    nc_outfile.setncattr('references', references)
 
     varname='img_pair_info'
 #    datatype=np.dtype('S1')
@@ -498,6 +478,8 @@
 #    var.setncattr('autoRIFT_software_version',version)
 
     for key in IMG_INFO_DICT:
+        if key == 'autoRIFT_software_version':
+            continue
         var.setncattr(key,IMG_INFO_DICT[key])
 
     
@@ -1429,7 +1411,7 @@
     nc_outfile.sync() # flush data to disk
     nc_outfile.close()
 
-
+    return out_nc_filename
 
 
 def rotate_vel2radar(rngind, azmind, vel_x, vel_y, swath_border, swath_border_full, GridSpacingX, ScaleChipSizeY, flag):
--- testautoRIFT_ISCE.py
+++ testautoRIFT_ISCE.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -394,7 +395,7 @@
 
 def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search_range, chip_size_min, chip_size_max,
                             offset2vx, offset2vy, stable_surface_mask, optical_flag, nc_sensor, mpflag, ncname,
-                            geogrid_run_info=None):
+                            geogrid_run_info=None, **kwargs):
 
     import numpy as np
     import time
@@ -494,7 +495,7 @@
     intermediate_nc_file = 'autoRIFT_intermediate.nc'
     
     if os.path.exists(intermediate_nc_file):
-        import netcdf_output as no
+        import hyp3_autorift.vend.netcdf_output as no
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = no.netCDF_read_intermediate(intermediate_nc_file)
     else:
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = runAutorift(
@@ -502,7 +503,7 @@
             noDataMask, optical_flag, nodata, mpflag, geogrid_run_info=geogrid_run_info,
         )
         if nc_sensor is not None:
-            import netcdf_output as no
+            import hyp3_autorift.vend.netcdf_output as no
             no.netCDF_packaging_intermediate(Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask, intermediate_nc_file)
 
 
@@ -539,8 +540,8 @@
     if SSM is not None:
         SSM[SEARCHLIMITX == 0] = False
 
-    import scipy.io as sio
-    sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
+    # import scipy.io as sio
+    # sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
 
     #####################  Uncomment for debug mode
 #    sio.savemat('debug.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX,'GridSpacingX':GridSpacingX,'ScaleChipSizeY':ScaleChipSizeY,'SearchLimitX':SEARCHLIMITX,'SearchLimitY':SEARCHLIMITY,'origSize':origSize,'noDataMask':noDataMask})
@@ -647,7 +648,7 @@
                 
                 if nc_sensor == "S":
                     swath_offset_bias_ref = [-0.01, 0.019, -0.0068, 0.006]
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     DX, DY, flight_direction_m, flight_direction_s = no.cal_swath_offset_bias(indir_m, xGrid, yGrid, VX, VY, DX, DY, nodata, tran, proj, GridSpacingX, ScaleChipSizeY, swath_offset_bias_ref)
                 
                 
@@ -786,17 +787,16 @@
                         dt = geogrid_run_info['dt']
                         epsg = geogrid_run_info['epsg']
 
-                    runCmd('topsinsar_filename.py')
-    #                import scipy.io as sio
-                    conts = sio.loadmat('topsinsar_filename.mat')
-                    master_filename = conts['master_filename'][0]
-                    slave_filename = conts['slave_filename'][0]
-                    master_dt = conts['master_dt'][0]
-                    slave_dt = conts['slave_dt'][0]
+                    from hyp3_autorift.io import get_topsinsar_config
+                    conts = get_topsinsar_config()
+                    master_filename = conts['reference_filename']
+                    slave_filename = conts['secondary_filename']
+                    master_dt = conts['reference_dt']
+                    slave_dt = conts['secondary_dt']
                     master_split = str.split(master_filename,'_')
                     slave_split = str.split(slave_filename,'_')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
                     coordinates = 'radar'
@@ -828,7 +828,33 @@
                     date_ct = d0 + (d1 - d0)/2
                     date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':'C','satellite_img1':master_split[0][1:3],'acquisition_img1':master_dt,'time_standard_img1':'UTC','absolute_orbit_number_img1':master_split[7],'mission_data_take_ID_img1':master_split[8],'product_unique_ID_img1':master_split[9][0:4],'flight_direction_img1':flight_direction_m,'mission_img2':slave_split[0][0],'sensor_img2':'C','satellite_img2':slave_split[0][1:3],'acquisition_img2':slave_dt,'time_standard_img2':'UTC','absolute_orbit_number_img2':slave_split[7],'mission_data_take_ID_img2':slave_split[8],'product_unique_ID_img2':slave_split[9][0:4],'flight_direction_img2':flight_direction_s,'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': 'C',
+                        'satellite_img1': master_split[0][1:3],
+                        'acquisition_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'absolute_orbit_number_img1': master_split[7],
+                        'mission_data_take_ID_img1': master_split[8],
+                        'product_unique_ID_img1': master_split[9][0:4],
+                        'flight_direction_img1': flight_direction_m,
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': 'C',
+                        'satellite_img2': slave_split[0][1:3],
+                        'acquisition_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'absolute_orbit_number_img2': slave_split[7],
+                        'mission_data_take_ID_img2': slave_split[8],
+                        'product_unique_ID_img2': slave_split[9][0:4],
+                        'flight_direction_img2': flight_direction_s,
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
+
                     error_vector = np.array([[0.0356, 0.0501, 0.0266, 0.0622, 0.0357, 0.0501],
                                              [0.5194, 1.1638, 0.3319, 1.3701, 0.5191, 1.1628]])
 
@@ -837,7 +863,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
                         DXref, DYref, rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "L":
@@ -869,7 +896,7 @@
 #                    master_time = str.split(str.split(runCmd('fgrep "SCENE_CENTER_TIME" '+master_MTL_path))[2][1:-2],':')
 #                    slave_time = str.split(str.split(runCmd('fgrep "SCENE_CENTER_TIME" '+slave_MTL_path))[2][1:-2],':')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -880,15 +907,15 @@
     #                out_nc_filename = 'Jakobshavn_opt.nc'
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename[0:-8]}_X_{slave_filename[0:-8]}" \
+                        out_nc_filename = f"./{master_filename[0:-7]}_X_{slave_filename[0:-7]}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
                     from datetime import datetime, timedelta
-                    d0 = datetime(np.int(master_split[3][0:4]),np.int(master_split[3][4:6]),np.int(master_split[3][6:8]))
-                    d1 = datetime(np.int(slave_split[3][0:4]),np.int(slave_split[3][4:6]),np.int(slave_split[3][6:8]))
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
                     date_dt_base = (d1 - d0).total_seconds() / timedelta(days=1).total_seconds()
                     date_dt = np.float64(date_dt_base)
                     if date_dt < 0:
@@ -900,7 +927,36 @@
                     master_dt = d0.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':master_split[0][1],'satellite_img1':np.float64(master_split[0][2:4]),'correction_level_img1':master_split[1],'path_img1':np.float64(master_split[2][0:3]),'row_img1':np.float64(master_split[2][3:6]),'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','processing_date_img1':master_split[4][0:8],'collection_number_img1':np.float64(master_split[5]),'collection_category_img1':master_split[6],'mission_img2':slave_split[0][0],'sensor_img2':slave_split[0][1],'satellite_img2':np.float64(slave_split[0][2:4]),'correction_level_img2':slave_split[1],'path_img2':np.float64(slave_split[2][0:3]),'row_img2':np.float64(slave_split[2][3:6]),'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','processing_date_img2':slave_split[4][0:8],'collection_number_img2':np.float64(slave_split[5]),'collection_category_img2':slave_split[6],'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': master_split[0][1],
+                        'satellite_img1': np.float64(master_split[0][2:4]),
+                        'correction_level_img1': master_split[1],
+                        'path_img1': np.float64(master_split[2][0:3]),
+                        'row_img1': np.float64(master_split[2][3:6]),
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'processing_date_img1': master_split[4][0:8],
+                        'collection_number_img1': np.float64(master_split[5]),
+                        'collection_category_img1': master_split[6],
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': slave_split[0][1],
+                        'satellite_img2': np.float64(slave_split[0][2:4]),
+                        'correction_level_img2': slave_split[1],
+                        'path_img2': np.float64(slave_split[2][0:3]),
+                        'row_img2': np.float64(slave_split[2][3:6]),
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'processing_date_img2': slave_split[4][0:8],
+                        'collection_number_img2': np.float64(slave_split[5]),
+                        'collection_category_img2': slave_split[6],
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -909,7 +965,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         None, None, XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "S2":
@@ -926,30 +983,17 @@
                         YPixelSize = geogrid_run_info['YPixelSize']
                         epsg = geogrid_run_info['epsg']
 
-                    master_path = indir_m
-                    slave_path = indir_s
+                    master_id = kwargs['reference_metadata']['id']
+                    slave_id = kwargs['secondary_metadata']['id']
 
-                    master_split = master_path.split('_')
-                    slave_split = slave_path.split('_')
+                    master_split = master_id.split('_')
+                    slave_split = slave_id.split('_')
                     
-                    import re
-                    if re.findall("://",master_path).__len__() > 0:
-                        master_filename_full = master_path.split('/')
-                        for item in master_filename_full:
-                            if re.findall("S2._",item).__len__() > 0:
-                                master_filename = item
-                        slave_filename_full = slave_path.split('/')
-                        for item in slave_filename_full:
-                            if re.findall("S2._",item).__len__() > 0:
-                                slave_filename = item
-                    else:
-                        master_filename = os.path.basename(master_path)[:-8]
-                        slave_filename = os.path.basename(slave_path)[:-8]
 
 #                    master_filename = master_split[0][-3:]+'_'+master_split[2]+'_'+master_split[4][:3]+'_'+os.path.basename(master_path)
 #                    slave_filename = slave_split[0][-3:]+'_'+slave_split[2]+'_'+slave_split[4][:3]+'_'+os.path.basename(slave_path)
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -959,15 +1003,15 @@
                         raise Exception('Input search range is all zero everywhere, thus no search conducted')
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename}_X_{slave_filename}" \
+                        out_nc_filename = f"./{master_id}_X_{slave_id}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
                     from datetime import datetime, timedelta
-                    d0 = datetime(np.int(master_split[2][0:4]),np.int(master_split[2][4:6]),np.int(master_split[2][6:8]))
-                    d1 = datetime(np.int(slave_split[2][0:4]),np.int(slave_split[2][4:6]),np.int(slave_split[2][6:8]))
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
                     date_dt_base = (d1 - d0).total_seconds() / timedelta(days=1).total_seconds()
                     date_dt = np.float64(date_dt_base)
                     if date_dt < 0:
@@ -979,7 +1023,24 @@
                     master_dt = d0.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][-3],'satellite_img1':master_split[0][-2:],'correction_level_img1':master_split[4][:3],'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','mission_img2':slave_split[0][-3],'satellite_img2':slave_split[0][-2:],'correction_level_img2':slave_split[4][:3],'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][-3],
+                        'satellite_img1': master_split[0][-2:],
+                        'correction_level_img1': master_split[4][:3],
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'mission_img2': slave_split[0][-3],
+                        'satellite_img2': slave_split[0][-2:],
+                        'correction_level_img2': slave_split[4][:3],
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -988,7 +1049,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         None, None, XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor is None:
--- testautoRIFT.py
+++ testautoRIFT.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -395,7 +396,7 @@
 
 def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search_range, chip_size_min, chip_size_max,
                             offset2vx, offset2vy, stable_surface_mask, optical_flag, nc_sensor, mpflag, ncname,
-                            geogrid_run_info=None):
+                            geogrid_run_info=None, **kwargs):
 
     import numpy as np
     import time
@@ -495,7 +496,7 @@
     intermediate_nc_file = 'autoRIFT_intermediate.nc'
     
     if os.path.exists(intermediate_nc_file):
-        import netcdf_output as no
+        import hyp3_autorift.vend.netcdf_output as no
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = no.netCDF_read_intermediate(intermediate_nc_file)
     else:
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = runAutorift(
@@ -503,7 +504,7 @@
             noDataMask, optical_flag, nodata, mpflag, geogrid_run_info=geogrid_run_info,
         )
         if nc_sensor is not None:
-            import netcdf_output as no
+            import hyp3_autorift.vend.netcdf_output as no
             no.netCDF_packaging_intermediate(Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask, intermediate_nc_file)
 
     if optical_flag == 0:
@@ -539,8 +540,8 @@
     if SSM is not None:
         SSM[SEARCHLIMITX == 0] = False
     
-    import scipy.io as sio
-    sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
+    # import scipy.io as sio
+    # sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
 
 #    #####################  Uncomment for debug mode
 #    sio.savemat('debug.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX,'ScaleChipSizeY':ScaleChipSizeY,'SearchLimitX':SEARCHLIMITX,'SearchLimitY':SEARCHLIMITY})
@@ -643,7 +644,7 @@
                 
                 if nc_sensor == "S":
                     swath_offset_bias_ref = [-0.01, 0.019, -0.0068, 0.006]
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     DX, DY, flight_direction_m, flight_direction_s = no.cal_swath_offset_bias(indir_m, xGrid, yGrid, VX, VY, DX, DY, nodata, tran, proj, GridSpacingX, ScaleChipSizeY, swath_offset_bias_ref)
                 
                 if geogrid_run_info is None:
@@ -781,17 +782,16 @@
                         dt = geogrid_run_info['dt']
                         epsg = geogrid_run_info['epsg']
 
-                    runCmd('topsinsar_filename.py')
-    #                import scipy.io as sio
-                    conts = sio.loadmat('topsinsar_filename.mat')
-                    master_filename = conts['master_filename'][0]
-                    slave_filename = conts['slave_filename'][0]
-                    master_dt = conts['master_dt'][0]
-                    slave_dt = conts['slave_dt'][0]
+                    from hyp3_autorift.io import get_topsinsar_config
+                    conts = get_topsinsar_config()
+                    master_filename = conts['reference_filename']
+                    slave_filename = conts['secondary_filename']
+                    master_dt = conts['reference_dt']
+                    slave_dt = conts['secondary_dt']
                     master_split = str.split(master_filename,'_')
                     slave_split = str.split(slave_filename,'_')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
                     coordinates = 'radar'
@@ -823,7 +823,33 @@
                     date_ct = d0 + (d1 - d0)/2
                     date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':'C','satellite_img1':master_split[0][1:3],'acquisition_img1':master_dt,'time_standard_img1':'UTC','absolute_orbit_number_img1':master_split[7],'mission_data_take_ID_img1':master_split[8],'product_unique_ID_img1':master_split[9][0:4],'flight_direction_img1':flight_direction_m,'mission_img2':slave_split[0][0],'sensor_img2':'C','satellite_img2':slave_split[0][1:3],'acquisition_img2':slave_dt,'time_standard_img2':'UTC','absolute_orbit_number_img2':slave_split[7],'mission_data_take_ID_img2':slave_split[8],'product_unique_ID_img2':slave_split[9][0:4],'flight_direction_img2':flight_direction_s,'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': 'C',
+                        'satellite_img1': master_split[0][1:3],
+                        'acquisition_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'absolute_orbit_number_img1': master_split[7],
+                        'mission_data_take_ID_img1': master_split[8],
+                        'product_unique_ID_img1': master_split[9][0:4],
+                        'flight_direction_img1': flight_direction_m,
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': 'C',
+                        'satellite_img2': slave_split[0][1:3],
+                        'acquisition_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'absolute_orbit_number_img2': slave_split[7],
+                        'mission_data_take_ID_img2': slave_split[8],
+                        'product_unique_ID_img2': slave_split[9][0:4],
+                        'flight_direction_img2': flight_direction_s,
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
+
                     error_vector = np.array([[0.0356, 0.0501, 0.0266, 0.0622, 0.0357, 0.0501],
                                              [0.5194, 1.1638, 0.3319, 1.3701, 0.5191, 1.1628]])
 
@@ -832,7 +858,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
                         DXref, DYref, rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "L":
@@ -864,7 +891,7 @@
 #                    master_time = str.split(str.split(runCmd('fgrep "SCENE_CENTER_TIME" '+master_MTL_path))[2][1:-2],':')
 #                    slave_time = str.split(str.split(runCmd('fgrep "SCENE_CENTER_TIME" '+slave_MTL_path))[2][1:-2],':')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -875,7 +902,7 @@
     #                out_nc_filename = 'Jakobshavn_opt.nc'
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename[0:-8]}_X_{slave_filename[0:-8]}" \
+                        out_nc_filename = f"./{master_filename[0:-7]}_X_{slave_filename[0:-7]}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
@@ -883,8 +910,8 @@
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
                     from datetime import datetime, timedelta
-                    d0 = datetime(np.int(master_split[3][0:4]),np.int(master_split[3][4:6]),np.int(master_split[3][6:8]))
-                    d1 = datetime(np.int(slave_split[3][0:4]),np.int(slave_split[3][4:6]),np.int(slave_split[3][6:8]))
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
                     date_dt_base = (d1 - d0).total_seconds() / timedelta(days=1).total_seconds()
                     date_dt = np.float64(date_dt_base)
                     if date_dt < 0:
@@ -896,7 +923,36 @@
                     master_dt = d0.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':master_split[0][1],'satellite_img1':np.float64(master_split[0][2:4]),'correction_level_img1':master_split[1],'path_img1':np.float64(master_split[2][0:3]),'row_img1':np.float64(master_split[2][3:6]),'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','processing_date_img1':master_split[4][0:8],'collection_number_img1':np.float64(master_split[5]),'collection_category_img1':master_split[6],'mission_img2':slave_split[0][0],'sensor_img2':slave_split[0][1],'satellite_img2':np.float64(slave_split[0][2:4]),'correction_level_img2':slave_split[1],'path_img2':np.float64(slave_split[2][0:3]),'row_img2':np.float64(slave_split[2][3:6]),'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','processing_date_img2':slave_split[4][0:8],'collection_number_img2':np.float64(slave_split[5]),'collection_category_img2':slave_split[6],'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': master_split[0][1],
+                        'satellite_img1': np.float64(master_split[0][2:4]),
+                        'correction_level_img1': master_split[1],
+                        'path_img1': np.float64(master_split[2][0:3]),
+                        'row_img1': np.float64(master_split[2][3:6]),
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'processing_date_img1': master_split[4][0:8],
+                        'collection_number_img1': np.float64(master_split[5]),
+                        'collection_category_img1': master_split[6],
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': slave_split[0][1],
+                        'satellite_img2': np.float64(slave_split[0][2:4]),
+                        'correction_level_img2': slave_split[1],
+                        'path_img2': np.float64(slave_split[2][0:3]),
+                        'row_img2': np.float64(slave_split[2][3:6]),
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'processing_date_img2': slave_split[4][0:8],
+                        'collection_number_img2': np.float64(slave_split[5]),
+                        'collection_category_img2': slave_split[6],
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -905,7 +961,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         None, None, XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "S2":
@@ -922,30 +979,17 @@
                         YPixelSize = geogrid_run_info['YPixelSize']
                         epsg = geogrid_run_info['epsg']
 
-                    master_path = indir_m
-                    slave_path = indir_s
+                    master_id = kwargs['reference_metadata']['id']
+                    slave_id = kwargs['secondary_metadata']['id']
 
-                    master_split = master_path.split('_')
-                    slave_split = slave_path.split('_')
+                    master_split = master_id.split('_')
+                    slave_split = slave_id.split('_')
                     
-                    import re
-                    if re.findall("://",master_path).__len__() > 0:
-                        master_filename_full = master_path.split('/')
-                        for item in master_filename_full:
-                            if re.findall("S2._",item).__len__() > 0:
-                                master_filename = item
-                        slave_filename_full = slave_path.split('/')
-                        for item in slave_filename_full:
-                            if re.findall("S2._",item).__len__() > 0:
-                                slave_filename = item
-                    else:
-                        master_filename = os.path.basename(master_path)[:-8]
-                        slave_filename = os.path.basename(slave_path)[:-8]
 
 #                    master_filename = master_split[0][-3:]+'_'+master_split[2]+'_'+master_split[4][:3]+'_'+os.path.basename(master_path)
 #                    slave_filename = slave_split[0][-3:]+'_'+slave_split[2]+'_'+slave_split[4][:3]+'_'+os.path.basename(slave_path)
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -955,15 +999,15 @@
                         raise Exception('Input search range is all zero everywhere, thus no search conducted')
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename}_X_{slave_filename}" \
+                        out_nc_filename = f"./{master_id}_X_{slave_id}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
                     from datetime import datetime, timedelta
-                    d0 = datetime(np.int(master_split[2][0:4]),np.int(master_split[2][4:6]),np.int(master_split[2][6:8]))
-                    d1 = datetime(np.int(slave_split[2][0:4]),np.int(slave_split[2][4:6]),np.int(slave_split[2][6:8]))
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
                     date_dt_base = (d1 - d0).total_seconds() / timedelta(days=1).total_seconds()
                     date_dt = np.float64(date_dt_base)
                     if date_dt < 0:
@@ -975,7 +1019,24 @@
                     master_dt = d0.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     slave_dt = d1.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][-3],'satellite_img1':master_split[0][-2:],'correction_level_img1':master_split[4][:3],'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','mission_img2':slave_split[0][-3],'satellite_img2':slave_split[0][-2:],'correction_level_img2':slave_split[4][:3],'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][-3],
+                        'satellite_img1': master_split[0][-2:],
+                        'correction_level_img1': master_split[4][:3],
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'mission_img2': slave_split[0][-3],
+                        'satellite_img2': slave_split[0][-2:],
+                        'correction_level_img2': slave_split[4][:3],
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -984,7 +1045,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         None, None, XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor is None:
--- testGeogrid_ISCE.py
+++ testGeogrid_ISCE.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -142,7 +143,7 @@
     return info
 
 
-def coregisterLoadMetadataOptical(indir_m, indir_s):
+def coregisterLoadMetadataOptical(indir_m, indir_s, **kwargs):
     '''
     Input file.
     '''
@@ -172,6 +173,9 @@
     if re.findall("L[CO]08_",DS.GetDescription()).__len__() > 0:
         nameString = os.path.basename(DS.GetDescription())
         info.time = nameString.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_m:
+        s2_name = kwargs['reference_metadata']['id']
+        info.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS.GetDescription()).__len__() > 0:
         info.time = DS.GetDescription().split('_')[2]
     else:
@@ -189,6 +193,9 @@
     if re.findall("L[CO]08_",DS1.GetDescription()).__len__() > 0:
         nameString1 = os.path.basename(DS1.GetDescription())
         info1.time = nameString1.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_s:
+        s2_name = kwargs['secondary_metadata']['id']
+        info1.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS1.GetDescription()).__len__() > 0:
         info1.time = DS1.GetDescription().split('_')[2]
     else:
--- testGeogridOptical.py
+++ testGeogridOptical.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -72,7 +73,7 @@
     pass
 
 
-def coregisterLoadMetadata(indir_m, indir_s):
+def coregisterLoadMetadata(indir_m, indir_s, **kwargs):
     '''
     Input file.
     '''
@@ -102,6 +103,9 @@
     if re.findall("L[CO]08_",DS.GetDescription()).__len__() > 0:
         nameString = os.path.basename(DS.GetDescription())
         info.time = nameString.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_m:
+        s2_name = kwargs['reference_metadata']['id']
+        info.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS.GetDescription()).__len__() > 0:
         info.time = DS.GetDescription().split('_')[2]
     else:
@@ -119,6 +123,9 @@
     if re.findall("L[CO]08_",DS1.GetDescription()).__len__() > 0:
         nameString1 = os.path.basename(DS1.GetDescription())
         info1.time = nameString1.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_s:
+        s2_name = kwargs['secondary_metadata']['id']
+        info1.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS1.GetDescription()).__len__() > 0:
         info1.time = DS1.GetDescription().split('_')[2]
     else:
