--- netcdf_output.py
+++ netcdf_output.py
@@ -4,38 +4,13 @@
 #Yang Lei, Jet Propulsion Laboratory
 #November 2017
 
-import xml.etree.ElementTree as ET
-#from numpy import *
 import numpy as np
-import scipy.io as sio
-##import commands
 import subprocess
 import os
-import time
-import argparse
-import pdb
-import os
-import isce
-import isceobj
-import shelve
-import string
-import sys
 import datetime
 import netCDF4
-from scipy import stats
 
-#def cmdLineParse():
-#    '''
-#    Command line parser.
-#    '''
-#    parser = argparse.ArgumentParser(description="Single-pair InSAR processing of Sentinel-1 data using ISCE modules")
-#
-#    return parser.parse_args()
-
-
-def runCmd(cmd):
-    out = subprocess.getoutput(cmd)
-    return out
+import hyp3_autorift
 
 def v_error_cal(vx_error, vy_error):
     vx = np.random.normal(0, vx_error, 1000000)
@@ -227,9 +202,11 @@
     return Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask
 
 
-def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1, SX, SY, offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref, rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type, detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied, dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector):
-    
-    
+def netCDF_packaging(VX, VY, DX, DY, INTERPMASK, CHIPSIZEX, CHIPSIZEY, SSM, SSM1, SX, SY,
+                     offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
+                     rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
+                     detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
+                     dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector, parameter_file):
     vx_mean_shift = offset2vx_1 * dx_mean_shift + offset2vx_2 * dy_mean_shift
     temp = vx_mean_shift
     temp[np.logical_not(SSM)] = np.nan
@@ -402,6 +379,29 @@
 #    CHIPSIZEY = np.round(np.clip(CHIPSIZEY, 0, 65535)).astype(np.uint16)
 #    INTERPMASK = np.round(np.clip(INTERPMASK, 0, 255)).astype(np.uint8)
 
+    source = f'NASA MEaSUREs ITS_LIVE project. Processed by ASF DAAC HyP3 {datetime.datetime.now().year} using the ' \
+             f'{hyp3_autorift.__name__} plugin version {hyp3_autorift.__version__} running autoRIFT version ' \
+             f'{IMG_INFO_DICT["autoRIFT_software_version"]}'
+    if pair_type == 'radar':
+        isce_version = subprocess.check_output('conda list | grep isce | awk \'{print $2}\'', shell=True, text=True)
+        source += f' built with ISCE version {isce_version.strip()}'
+    if IMG_INFO_DICT['mission_img1'].startswith('S'):
+        source += f'. Contains modified Copernicus Sentinel data {IMG_INFO_DICT["date_center"][0:4]}, processed by ESA'
+    if IMG_INFO_DICT['mission_img1'].startswith('L'):
+        source += f'. Landsat-{IMG_INFO_DICT["satellite_img1"]:.0f} images courtesy of the U.S. Geological Survey'
+
+    references = 'When using this data, please acknowledge the source (see global source attribute) and cite:\n' \
+                 '* Gardner, A. S., Moholdt, G., Scambos, T., Fahnestock, M., Ligtenberg, S., van den Broeke, M.,\n' \
+                 '  and Nilsson, J., 2018. Increased West Antarctic and unchanged East Antarctic ice discharge over\n' \
+                 '  the last 7 years. The Cryosphere, 12, p.521. https://doi.org/10.5194/tc-12-521-2018\n' \
+                 '* Lei, Y., Gardner, A. and Agram, P., 2021. Autonomous Repeat Image Feature Tracking (autoRIFT)\n' \
+                 '  and Its Application for Tracking Ice Displacement. Remote Sensing, 13(4), p.749.\n' \
+                 '  https://doi.org/10.3390/rs13040749\n' \
+                 '\n' \
+                 'Additionally, DOI\'s are provided for the software used to generate this data:\n' \
+                 '* autoRIFT: https://doi.org/10.5281/zenodo.4025445\n' \
+                 '* HyP3 autoRIFT plugin: https://doi.org/10.5281/zenodo.4037016\n' \
+                 '* HyP3 processing environment: https://doi.org/10.5281/zenodo.3962581'
     
     tran = [tran[0] + tran[1]/2, tran[1], 0.0, tran[3] + tran[5]/2, 0.0, tran[5]]
     
@@ -414,35 +414,15 @@
     nc_outfile.setncattr('Conventions','CF-1.6')
     nc_outfile.setncattr('date_created',datetime.datetime.now().strftime("%d-%b-%Y %H:%M:%S"))
     nc_outfile.setncattr('title',title)
-    nc_outfile.setncattr('author',author)
-    nc_outfile.setncattr('institution',institution)
-#    nc_outfile.setncattr('Software',version)
+    nc_outfile.setncattr('autoRIFT_software_version', IMG_INFO_DICT["autoRIFT_software_version"])
+    nc_outfile.setncattr('autoRIFT_parameter_file', parameter_file)
     nc_outfile.setncattr('scene_pair_type',pair_type)
     nc_outfile.setncattr('motion_detection_method',detection_method)
     nc_outfile.setncattr('motion_coordinates',coordinates)
-
-    # if we were copying from an nc file, we would...
-    # for attr in vv_nc_basefile.ncattrs():
-    #     nc_outfile.setncattr(attr,vv_nc_basefile.getncattr(attr))
-    
-#    from topsApp import TopsInSAR
-#    insar = TopsInSAR(name="topsApp")
-#    insar.configure()
-#    master_filename = os.path.basename(insar.master.safe[0])
-#    slave_filename = os.path.basename(insar.slave.safe[0])
-
-#    import topsinsar_filename as tf
-#    master_filename, slave_filename = tf.loadXml()
-
-
-#    runCmd('topsinsar_filename.py')
-#    import scipy.io as sio
-#    conts = sio.loadmat('topsinsar_filename.mat')
-#    master_filename = conts['master_filename'][0]
-#    slave_filename = conts['slave_filename'][0]
-#    master_split = str.split(master_filename,'_')
-#    slave_split = str.split(slave_filename,'_')
-
+    nc_outfile.setncattr('author', author)
+    nc_outfile.setncattr('institution', institution)
+    nc_outfile.setncattr('source', source)
+    nc_outfile.setncattr('references', references)
 
     varname='img_pair_info'
 #    datatype=np.dtype('S1')
@@ -486,6 +466,8 @@
 #    var.setncattr('autoRIFT_software_version',version)
 
     for key in IMG_INFO_DICT:
+        if key == 'autoRIFT_software_version':
+            continue
         var.setncattr(key,IMG_INFO_DICT[key])
 
     
@@ -1417,7 +1399,7 @@
     nc_outfile.sync() # flush data to disk
     nc_outfile.close()
 
-
+    return out_nc_filename
 
 
 def rotate_vel2radar(rngind, azmind, vel_x, vel_y, swath_border, swath_border_full, GridSpacingX, ScaleChipSizeY, flag):
--- testautoRIFT_ISCE.py
+++ testautoRIFT_ISCE.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -394,7 +395,7 @@
 
 def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search_range, chip_size_min, chip_size_max,
                             offset2vx, offset2vy, stable_surface_mask, optical_flag, nc_sensor, mpflag, ncname,
-                            geogrid_run_info=None):
+                            geogrid_run_info=None, **kwargs):
 
     import numpy as np
     import time
@@ -485,7 +486,6 @@
         ds = gdal.Open(stable_surface_mask)
         band = ds.GetRasterBand(1)
         SSM = band.ReadAsArray()
-#        SSM = SSM * 0
         SSM = SSM.astype('bool')
         band=None
         ds=None
@@ -494,7 +494,7 @@
     intermediate_nc_file = 'autoRIFT_intermediate.nc'
     
     if os.path.exists(intermediate_nc_file):
-        import netcdf_output as no
+        import hyp3_autorift.vend.netcdf_output as no
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = no.netCDF_read_intermediate(intermediate_nc_file)
     else:
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = runAutorift(
@@ -502,10 +502,9 @@
             noDataMask, optical_flag, nodata, mpflag, geogrid_run_info=geogrid_run_info,
         )
         if nc_sensor is not None:
-            import netcdf_output as no
+            import hyp3_autorift.vend.netcdf_output as no
             no.netCDF_packaging_intermediate(Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask, intermediate_nc_file)
 
-
     if optical_flag == 0:
         Dy = -Dy
 
@@ -539,8 +538,8 @@
     if SSM is not None:
         SSM[SEARCHLIMITX == 0] = False
 
-    import scipy.io as sio
-    sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
+    # import scipy.io as sio
+    # sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
 
     #####################  Uncomment for debug mode
 #    sio.savemat('debug.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX,'GridSpacingX':GridSpacingX,'ScaleChipSizeY':ScaleChipSizeY,'SearchLimitX':SEARCHLIMITX,'SearchLimitY':SEARCHLIMITY,'origSize':origSize,'noDataMask':noDataMask})
@@ -647,10 +645,9 @@
                 
                 if nc_sensor == "S":
                     swath_offset_bias_ref = [-0.01, 0.019, -0.0068, 0.006]
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     DX, DY, flight_direction_m, flight_direction_s = no.cal_swath_offset_bias(indir_m, xGrid, yGrid, VX, VY, DX, DY, nodata, tran, proj, GridSpacingX, ScaleChipSizeY, swath_offset_bias_ref)
                 
-                
                 if geogrid_run_info is None:
                     vxrefname = str.split(runCmd('fgrep "Velocities:" testGeogrid.txt'))[1]
                     vyrefname = str.split(runCmd('fgrep "Velocities:" testGeogrid.txt'))[2]
@@ -786,17 +783,16 @@
                         dt = geogrid_run_info['dt']
                         epsg = geogrid_run_info['epsg']
 
-                    runCmd('topsinsar_filename.py')
-    #                import scipy.io as sio
-                    conts = sio.loadmat('topsinsar_filename.mat')
-                    master_filename = conts['master_filename'][0]
-                    slave_filename = conts['slave_filename'][0]
-                    master_dt = conts['master_dt'][0]
-                    slave_dt = conts['slave_dt'][0]
+                    from hyp3_autorift.io import get_topsinsar_config
+                    conts = get_topsinsar_config()
+                    master_filename = conts['reference_filename']
+                    slave_filename = conts['secondary_filename']
+                    master_dt = conts['reference_dt']
+                    slave_dt = conts['secondary_dt']
                     master_split = str.split(master_filename,'_')
                     slave_split = str.split(slave_filename,'_')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
                     coordinates = 'radar'
@@ -831,7 +827,33 @@
                         date_ct = d0 + (d1 - d0)/2
                         date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':'C','satellite_img1':master_split[0][1:3],'acquisition_img1':master_dt,'time_standard_img1':'UTC','absolute_orbit_number_img1':master_split[7],'mission_data_take_ID_img1':master_split[8],'product_unique_ID_img1':master_split[9][0:4],'flight_direction_img1':flight_direction_m,'mission_img2':slave_split[0][0],'sensor_img2':'C','satellite_img2':slave_split[0][1:3],'acquisition_img2':slave_dt,'time_standard_img2':'UTC','absolute_orbit_number_img2':slave_split[7],'mission_data_take_ID_img2':slave_split[8],'product_unique_ID_img2':slave_split[9][0:4],'flight_direction_img2':flight_direction_s,'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': 'C',
+                        'satellite_img1': master_split[0][1:3],
+                        'acquisition_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'absolute_orbit_number_img1': master_split[7],
+                        'mission_data_take_ID_img1': master_split[8],
+                        'product_unique_ID_img1': master_split[9][0:4],
+                        'flight_direction_img1': flight_direction_m,
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': 'C',
+                        'satellite_img2': slave_split[0][1:3],
+                        'acquisition_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'absolute_orbit_number_img2': slave_split[7],
+                        'mission_data_take_ID_img2': slave_split[8],
+                        'product_unique_ID_img2': slave_split[9][0:4],
+                        'flight_direction_img2': flight_direction_s,
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
+
                     error_vector = np.array([[0.0356, 0.0501, 0.0266, 0.0622, 0.0357, 0.0501],
                                              [0.5194, 1.1638, 0.3319, 1.3701, 0.5191, 1.1628]])
 
@@ -840,7 +862,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
                         rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "L":
@@ -878,7 +901,7 @@
                     master_time = time1(int(master_time[0]),int(master_time[1]),int(float(master_time[2])))
                     slave_time = time1(int(slave_time[0]),int(slave_time[1]),int(float(slave_time[2])))
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -889,7 +912,7 @@
     #                out_nc_filename = 'Jakobshavn_opt.nc'
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename[0:-8]}_X_{slave_filename[0:-8]}" \
+                        out_nc_filename = f"./{master_filename[0:-7]}_X_{slave_filename[0:-7]}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
@@ -893,26 +916,56 @@
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
+
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
-                    from datetime import date
-                    d0 = date(np.int(master_split[3][0:4]),np.int(master_split[3][4:6]),np.int(master_split[3][6:8]))
-                    d1 = date(np.int(slave_split[3][0:4]),np.int(slave_split[3][4:6]),np.int(slave_split[3][6:8]))
+                    from datetime import datetime
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
                     date_dt_base = d1 - d0
                     date_dt = np.float64(date_dt_base.days)
                     if date_dt < 0:
                         raise Exception('Input image 1 must be older than input image 2')
                     if date_dt_base.days < 0:
                         date_ct = d1 + (d0 - d1)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     else:
                         date_ct = d0 + (d1 - d0)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    master_dt = master_split[3][0:8] + master_time.strftime("T%H:%M:%S")
-                    slave_dt = slave_split[3][0:8] + slave_time.strftime("T%H:%M:%S")
+                    master_dt = d0.strftime('%Y%m%dT%H:%M:%S.%f')
+                    slave_dt = d1.strftime('%Y%m%dT%H:%M:%S.%f')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':master_split[0][1],'satellite_img1':np.float64(master_split[0][2:4]),'correction_level_img1':master_split[1],'path_img1':np.float64(master_split[2][0:3]),'row_img1':np.float64(master_split[2][3:6]),'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','processing_date_img1':master_split[4][0:8],'collection_number_img1':np.float64(master_split[5]),'collection_category_img1':master_split[6],'mission_img2':slave_split[0][0],'sensor_img2':slave_split[0][1],'satellite_img2':np.float64(slave_split[0][2:4]),'correction_level_img2':slave_split[1],'path_img2':np.float64(slave_split[2][0:3]),'row_img2':np.float64(slave_split[2][3:6]),'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','processing_date_img2':slave_split[4][0:8],'collection_number_img2':np.float64(slave_split[5]),'collection_category_img2':slave_split[6],'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': master_split[0][1],
+                        'satellite_img1': np.float64(master_split[0][2:4]),
+                        'correction_level_img1': master_split[1],
+                        'path_img1': np.float64(master_split[2][0:3]),
+                        'row_img1': np.float64(master_split[2][3:6]),
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'processing_date_img1': master_split[4][0:8],
+                        'collection_number_img1': np.float64(master_split[5]),
+                        'collection_category_img1': master_split[6],
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': slave_split[0][1],
+                        'satellite_img2': np.float64(slave_split[0][2:4]),
+                        'correction_level_img2': slave_split[1],
+                        'path_img2': np.float64(slave_split[2][0:3]),
+                        'row_img2': np.float64(slave_split[2][3:6]),
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'processing_date_img2': slave_split[4][0:8],
+                        'collection_number_img2': np.float64(slave_split[5]),
+                        'collection_category_img2': slave_split[6],
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -921,7 +974,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "S2":
@@ -941,8 +995,8 @@
                     master_path = indir_m
                     slave_path = indir_s
 
-                    master_split = master_path.split('_')
-                    slave_split = slave_path.split('_')
+                    master_split = kwargs['reference_metadata']['id'].split('_')
+                    slave_split = kwargs['secondary_metadata']['id'].split('_')
 
                     master_filename = master_split[0][-3:]+'_'+master_split[2]+'_'+master_split[4][:3]+'_'+os.path.basename(master_path)
                     slave_filename = slave_split[0][-3:]+'_'+slave_split[2]+'_'+slave_split[4][:3]+'_'+os.path.basename(slave_path)
@@ -954,7 +1008,7 @@
                     master_time = time1(int(master_time[0]),int(master_time[1]),int(float(master_time[2])))
                     slave_time = time1(int(slave_time[0]),int(slave_time[1]),int(float(slave_time[2])))
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -970,24 +1024,41 @@
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
-                    from datetime import date
-                    d0 = date(np.int(master_split[2][0:4]),np.int(master_split[2][4:6]),np.int(master_split[2][6:8]))
-                    d1 = date(np.int(slave_split[2][0:4]),np.int(slave_split[2][4:6]),np.int(slave_split[2][6:8]))
+                    from datetime import datetime
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
                     date_dt_base = d1 - d0
                     date_dt = np.float64(date_dt_base.days)
                     if date_dt < 0:
                         raise Exception('Input image 1 must be older than input image 2')
                     if date_dt_base.days < 0:
                         date_ct = d1 + (d0 - d1)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     else:
                         date_ct = d0 + (d1 - d0)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    master_dt = master_split[2] + master_time.strftime("T%H:%M:%S")
-                    slave_dt = slave_split[2] + slave_time.strftime("T%H:%M:%S")
+                    master_dt = d0.strftime('%Y%m%dT%H:%M:%S')
+                    slave_dt = d1.strftime('%Y%m%dT%H:%M:%S')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][-3],'satellite_img1':master_split[0][-2:],'correction_level_img1':master_split[4][:3],'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','mission_img2':slave_split[0][-3],'satellite_img2':slave_split[0][-2:],'correction_level_img2':slave_split[4][:3],'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][-3],
+                        'satellite_img1': master_split[0][-2:],
+                        'correction_level_img1': master_split[4][:3],
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'mission_img2': slave_split[0][-3],
+                        'satellite_img2': slave_split[0][-2:],
+                        'correction_level_img2': slave_split[4][:3],
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -996,7 +1067,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor is None:
--- testautoRIFT.py
+++ testautoRIFT.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -395,7 +396,7 @@
 
 def generateAutoriftProduct(indir_m, indir_s, grid_location, init_offset, search_range, chip_size_min, chip_size_max,
                             offset2vx, offset2vy, stable_surface_mask, optical_flag, nc_sensor, mpflag, ncname,
-                            geogrid_run_info=None):
+                            geogrid_run_info=None, **kwargs):
 
     import numpy as np
     import time
@@ -491,11 +492,10 @@
         ds=None
 
 
-
     intermediate_nc_file = 'autoRIFT_intermediate.nc'
     
     if os.path.exists(intermediate_nc_file):
-        import netcdf_output as no
+        import hyp3_autorift.vend.netcdf_output as no
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = no.netCDF_read_intermediate(intermediate_nc_file)
     else:
         Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask = runAutorift(
@@ -503,7 +503,7 @@
             noDataMask, optical_flag, nodata, mpflag, geogrid_run_info=geogrid_run_info,
         )
         if nc_sensor is not None:
-            import netcdf_output as no
+            import hyp3_autorift.vend.netcdf_output as no
             no.netCDF_packaging_intermediate(Dx, Dy, InterpMask, ChipSizeX, GridSpacingX, ScaleChipSizeY, SearchLimitX, SearchLimitY, origSize, noDataMask, intermediate_nc_file)
 
     if optical_flag == 0:
@@ -539,8 +539,8 @@
     if SSM is not None:
         SSM[SEARCHLIMITX == 0] = False
     
-    import scipy.io as sio
-    sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
+    # import scipy.io as sio
+    # sio.savemat('offset.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX})
 
 #    #####################  Uncomment for debug mode
 #    sio.savemat('debug.mat',{'Dx':DX,'Dy':DY,'InterpMask':INTERPMASK,'ChipSizeX':CHIPSIZEX,'ScaleChipSizeY':ScaleChipSizeY,'SearchLimitX':SEARCHLIMITX,'SearchLimitY':SEARCHLIMITY})
@@ -643,7 +643,7 @@
                 
                 if nc_sensor == "S":
                     swath_offset_bias_ref = [-0.01, 0.019, -0.0068, 0.006]
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     DX, DY, flight_direction_m, flight_direction_s = no.cal_swath_offset_bias(indir_m, xGrid, yGrid, VX, VY, DX, DY, nodata, tran, proj, GridSpacingX, ScaleChipSizeY, swath_offset_bias_ref)
                 
                 if geogrid_run_info is None:
@@ -781,17 +781,16 @@
                         dt = geogrid_run_info['dt']
                         epsg = geogrid_run_info['epsg']
 
-                    runCmd('topsinsar_filename.py')
-    #                import scipy.io as sio
-                    conts = sio.loadmat('topsinsar_filename.mat')
-                    master_filename = conts['master_filename'][0]
-                    slave_filename = conts['slave_filename'][0]
-                    master_dt = conts['master_dt'][0]
-                    slave_dt = conts['slave_dt'][0]
+                    from hyp3_autorift.io import get_topsinsar_config
+                    conts = get_topsinsar_config()
+                    master_filename = conts['reference_filename']
+                    slave_filename = conts['secondary_filename']
+                    master_dt = conts['reference_dt']
+                    slave_dt = conts['secondary_dt']
                     master_split = str.split(master_filename,'_')
                     slave_split = str.split(slave_filename,'_')
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'radar'
                     detection_method = 'feature'
                     coordinates = 'radar'
@@ -826,7 +825,33 @@
                         date_ct = d0 + (d1 - d0)/2
                         date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':'C','satellite_img1':master_split[0][1:3],'acquisition_img1':master_dt,'time_standard_img1':'UTC','absolute_orbit_number_img1':master_split[7],'mission_data_take_ID_img1':master_split[8],'product_unique_ID_img1':master_split[9][0:4],'flight_direction_img1':flight_direction_m,'mission_img2':slave_split[0][0],'sensor_img2':'C','satellite_img2':slave_split[0][1:3],'acquisition_img2':slave_dt,'time_standard_img2':'UTC','absolute_orbit_number_img2':slave_split[7],'mission_data_take_ID_img2':slave_split[8],'product_unique_ID_img2':slave_split[9][0:4],'flight_direction_img2':flight_direction_s,'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': 'C',
+                        'satellite_img1': master_split[0][1:3],
+                        'acquisition_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'absolute_orbit_number_img1': master_split[7],
+                        'mission_data_take_ID_img1': master_split[8],
+                        'product_unique_ID_img1': master_split[9][0:4],
+                        'flight_direction_img1': flight_direction_m,
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': 'C',
+                        'satellite_img2': slave_split[0][1:3],
+                        'acquisition_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'absolute_orbit_number_img2': slave_split[7],
+                        'mission_data_take_ID_img2': slave_split[8],
+                        'product_unique_ID_img2': slave_split[9][0:4],
+                        'flight_direction_img2': flight_direction_s,
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
+
                     error_vector = np.array([[0.0356, 0.0501, 0.0266, 0.0622, 0.0357, 0.0501],
                                              [0.5194, 1.1638, 0.3319, 1.3701, 0.5191, 1.1628]])
 
@@ -835,7 +860,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, offset2vr, offset2va, MM, VXref, VYref,
                         rangePixelSize, azimuthPixelSize, dt, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "L":
@@ -873,7 +899,7 @@
                     master_time = time1(int(master_time[0]),int(master_time[1]),int(float(master_time[2])))
                     slave_time = time1(int(slave_time[0]),int(slave_time[1]),int(float(slave_time[2])))
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -884,31 +910,60 @@
     #                out_nc_filename = 'Jakobshavn_opt.nc'
                     PPP = roi_valid_percentage * 100
                     if ncname is None:
-                        out_nc_filename = f"./{master_filename[0:-8]}_X_{slave_filename[0:-8]}" \
+                        out_nc_filename = f"./{master_filename[0:-7]}_X_{slave_filename[0:-7]}" \
                                           f"_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     else:
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
 
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
-                    from datetime import date
-                    d0 = date(np.int(master_split[3][0:4]),np.int(master_split[3][4:6]),np.int(master_split[3][6:8]))
-                    d1 = date(np.int(slave_split[3][0:4]),np.int(slave_split[3][4:6]),np.int(slave_split[3][6:8]))
+                    from datetime import datetime
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ')
                     date_dt_base = d1 - d0
                     date_dt = np.float64(date_dt_base.days)
                     if date_dt < 0:
                         raise Exception('Input image 1 must be older than input image 2')
                     if date_dt_base.days < 0:
                         date_ct = d1 + (d0 - d1)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     else:
                         date_ct = d0 + (d1 - d0)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    master_dt = master_split[3][0:8] + master_time.strftime("T%H:%M:%S")
-                    slave_dt = slave_split[3][0:8] + slave_time.strftime("T%H:%M:%S")
+                    master_dt = d0.strftime('%Y%m%dT%H:%M:%S.%f')
+                    slave_dt = d1.strftime('%Y%m%dT%H:%M:%S.%f')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][0],'sensor_img1':master_split[0][1],'satellite_img1':np.float64(master_split[0][2:4]),'correction_level_img1':master_split[1],'path_img1':np.float64(master_split[2][0:3]),'row_img1':np.float64(master_split[2][3:6]),'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','processing_date_img1':master_split[4][0:8],'collection_number_img1':np.float64(master_split[5]),'collection_category_img1':master_split[6],'mission_img2':slave_split[0][0],'sensor_img2':slave_split[0][1],'satellite_img2':np.float64(slave_split[0][2:4]),'correction_level_img2':slave_split[1],'path_img2':np.float64(slave_split[2][0:3]),'row_img2':np.float64(slave_split[2][3:6]),'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','processing_date_img2':slave_split[4][0:8],'collection_number_img2':np.float64(slave_split[5]),'collection_category_img2':slave_split[6],'date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][0],
+                        'sensor_img1': master_split[0][1],
+                        'satellite_img1': np.float64(master_split[0][2:4]),
+                        'correction_level_img1': master_split[1],
+                        'path_img1': np.float64(master_split[2][0:3]),
+                        'row_img1': np.float64(master_split[2][3:6]),
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'processing_date_img1': master_split[4][0:8],
+                        'collection_number_img1': np.float64(master_split[5]),
+                        'collection_category_img1': master_split[6],
+                        'mission_img2': slave_split[0][0],
+                        'sensor_img2': slave_split[0][1],
+                        'satellite_img2': np.float64(slave_split[0][2:4]),
+                        'correction_level_img2': slave_split[1],
+                        'path_img2': np.float64(slave_split[2][0:3]),
+                        'row_img2': np.float64(slave_split[2][3:6]),
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'processing_date_img2': slave_split[4][0:8],
+                        'collection_number_img2': np.float64(slave_split[5]),
+                        'collection_category_img2': slave_split[6],
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -917,7 +972,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor == "S2":
@@ -937,8 +993,8 @@
                     master_path = indir_m
                     slave_path = indir_s
 
-                    master_split = master_path.split('_')
-                    slave_split = slave_path.split('_')
+                    master_split = kwargs['reference_metadata']['id'].split('_')
+                    slave_split = kwargs['secondary_metadata']['id'].split('_')
 
                     master_filename = master_split[0][-3:]+'_'+master_split[2]+'_'+master_split[4][:3]+'_'+os.path.basename(master_path)
                     slave_filename = slave_split[0][-3:]+'_'+slave_split[2]+'_'+slave_split[4][:3]+'_'+os.path.basename(slave_path)
@@ -950,7 +1006,7 @@
                     master_time = time1(int(master_time[0]),int(master_time[1]),int(float(master_time[2])))
                     slave_time = time1(int(slave_time[0]),int(slave_time[1]),int(float(slave_time[2])))
 
-                    import netcdf_output as no
+                    import hyp3_autorift.vend.netcdf_output as no
                     pair_type = 'optical'
                     detection_method = 'feature'
                     coordinates = 'map'
@@ -966,24 +1022,41 @@
                         out_nc_filename = f"{ncname}_G{gridspacingx:04.0f}V02_P{np.floor(PPP):03.0f}.nc"
                     CHIPSIZEY = np.round(CHIPSIZEX * ScaleChipSizeY / 2) * 2
 
-                    from datetime import date
-                    d0 = date(np.int(master_split[2][0:4]),np.int(master_split[2][4:6]),np.int(master_split[2][6:8]))
-                    d1 = date(np.int(slave_split[2][0:4]),np.int(slave_split[2][4:6]),np.int(slave_split[2][6:8]))
+                    from datetime import datetime
+                    d0 = datetime.strptime(kwargs['reference_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
+                    d1 = datetime.strptime(kwargs['secondary_metadata']['properties']['datetime'], '%Y-%m-%dT%H:%M:%SZ')
                     date_dt_base = d1 - d0
                     date_dt = np.float64(date_dt_base.days)
                     if date_dt < 0:
                         raise Exception('Input image 1 must be older than input image 2')
                     if date_dt_base.days < 0:
                         date_ct = d1 + (d0 - d1)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
                     else:
                         date_ct = d0 + (d1 - d0)/2
-                        date_center = date_ct.strftime("%Y%m%d")
+                        date_center = date_ct.strftime("%Y%m%dT%H:%M:%S.%f").rstrip('0')
 
-                    master_dt = master_split[2] + master_time.strftime("T%H:%M:%S")
-                    slave_dt = slave_split[2] + slave_time.strftime("T%H:%M:%S")
+                    master_dt = d0.strftime('%Y%m%dT%H:%M:%S')
+                    slave_dt = d1.strftime('%Y%m%dT%H:%M:%S')
 
-                    IMG_INFO_DICT = {'mission_img1':master_split[0][-3],'satellite_img1':master_split[0][-2:],'correction_level_img1':master_split[4][:3],'acquisition_date_img1':master_dt,'time_standard_img1':'UTC','mission_img2':slave_split[0][-3],'satellite_img2':slave_split[0][-2:],'correction_level_img2':slave_split[4][:3],'acquisition_date_img2':slave_dt,'time_standard_img2':'UTC','date_dt':date_dt,'date_center':date_center,'latitude':cen_lat,'longitude':cen_lon,'roi_valid_percentage':PPP,'autoRIFT_software_version':version}
+                    IMG_INFO_DICT = {
+                        'mission_img1': master_split[0][-3],
+                        'satellite_img1': master_split[0][-2:],
+                        'correction_level_img1': master_split[4][:3],
+                        'acquisition_date_img1': master_dt,
+                        'time_standard_img1': 'UTC',
+                        'mission_img2': slave_split[0][-3],
+                        'satellite_img2': slave_split[0][-2:],
+                        'correction_level_img2': slave_split[4][:3],
+                        'acquisition_date_img2': slave_dt,
+                        'time_standard_img2': 'UTC',
+                        'date_dt': date_dt,
+                        'date_center': date_center,
+                        'latitude': cen_lat,
+                        'longitude': cen_lon,
+                        'roi_valid_percentage': PPP,
+                        'autoRIFT_software_version': version
+                    }
 
                     error_vector = np.array([25.5,25.5])
 
@@ -992,7 +1065,8 @@
                         offset2vx_1, offset2vx_2, offset2vy_1, offset2vy_2, None, None, MM, VXref, VYref,
                         XPixelSize, YPixelSize, None, epsg, srs, tran, out_nc_filename, pair_type,
                         detection_method, coordinates, IMG_INFO_DICT, stable_count, stable_count1, stable_shift_applied,
-                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector
+                        dx_mean_shift, dy_mean_shift, dx_mean_shift1, dy_mean_shift1, error_vector,
+                        parameter_file=kwargs['parameter_file'],
                     )
 
                 elif nc_sensor is None:
--- testGeogrid_ISCE.py
+++ testGeogrid_ISCE.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -142,7 +143,7 @@
     return info
 
 
-def coregisterLoadMetadataOptical(indir_m, indir_s):
+def coregisterLoadMetadataOptical(indir_m, indir_s, **kwargs):
     '''
     Input file.
     '''
@@ -172,6 +173,9 @@
     if re.findall("L[CO]08_",DS.GetDescription()).__len__() > 0:
         nameString = os.path.basename(DS.GetDescription())
         info.time = nameString.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_m:
+        s2_name = kwargs['reference_metadata']['id']
+        info.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS.GetDescription()).__len__() > 0:
         info.time = DS.GetDescription().split('_')[2]
     else:
@@ -189,6 +193,9 @@
     if re.findall("L[CO]08_",DS1.GetDescription()).__len__() > 0:
         nameString1 = os.path.basename(DS1.GetDescription())
         info1.time = nameString1.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_s:
+        s2_name = kwargs['secondary_metadata']['id']
+        info1.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS1.GetDescription()).__len__() > 0:
         info1.time = DS1.GetDescription().split('_')[2]
     else:
--- testGeogridOptical.py
+++ testGeogridOptical.py
@@ -2,6 +2,7 @@
 
 #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 # Copyright 2019 California Institute of Technology. ALL RIGHTS RESERVED.
+# Modifications Copyright 2021 Alaska Satellite Facility
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -72,7 +73,7 @@
     pass
 
 
-def coregisterLoadMetadata(indir_m, indir_s):
+def coregisterLoadMetadata(indir_m, indir_s, **kwargs):
     '''
     Input file.
     '''
@@ -102,6 +103,9 @@
     if re.findall("L[CO]08_",DS.GetDescription()).__len__() > 0:
         nameString = os.path.basename(DS.GetDescription())
         info.time = nameString.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_m:
+        s2_name = kwargs['reference_metadata']['id']
+        info.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS.GetDescription()).__len__() > 0:
         info.time = DS.GetDescription().split('_')[2]
     else:
@@ -119,6 +123,9 @@
     if re.findall("L[CO]08_",DS1.GetDescription()).__len__() > 0:
         nameString1 = os.path.basename(DS1.GetDescription())
         info1.time = nameString1.split('_')[3]
+    elif 'sentinel-s2-l1c' in indir_s:
+        s2_name = kwargs['secondary_metadata']['id']
+        info1.time = s2_name.split('_')[2]
     elif re.findall("S2._",DS1.GetDescription()).__len__() > 0:
         info1.time = DS1.GetDescription().split('_')[2]
     else:
