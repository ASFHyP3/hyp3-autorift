{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using the Python SDK for autoRIFT\n",
    "\n",
    "HyP3's Python SDK `hyp3_sdk` provides a convenience wrapper around the HyP3 API and HyP3 jobs.\n",
    "\n",
    "\n",
    "The HyP3 SDK can be installed using [Anaconda/Miniconda (recommended)](https://docs.conda.io/projects/conda/en/latest/user-guide/install/download.html#anaconda-or-miniconda)\n",
    "via [`conda`](https://anaconda.org/conda-forge/hyp3_sdk):\n",
    "\n",
    "```\n",
    "conda install -c conda-forge hyp3_sdk\n",
    "```\n",
    "\n",
    "Or using [`pip`](https://pypi.org/project/hyp3-sdk/):\n",
    "\n",
    "```\n",
    "python -m pip install hyp3_sdk\n",
    "```\n",
    "\n",
    "Full documentation of the SDK can be found in the [HyP3 documentation](https://hyp3-docs.asf.alaska.edu/using/sdk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "import hyp3_sdk as sdk\n",
    "\n",
    "AUTORIFT_API = 'https://hyp3-autorift.asf.alaska.edu/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticating to the API\n",
    "\n",
    "The SDK will pull your [NASA Earthdata Login](https://urs.earthdata.nasa.gov/) credentials out of `~/.netrc` if they\n",
    "exist by default, or you can pass your credentials in directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .netrc\n",
    "hyp3 = sdk.HyP3(AUTORIFT_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or enter your credentials\n",
    "from getpass import getpass\n",
    "username = 'MY_EDL_USERNAME'\n",
    "password = getpass()  # will prompt for a password\n",
    "hyp3 = sdk.HyP3(AUTORIFT_API, username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting jobs\n",
    "\n",
    "AutoRIFT jobs can be submitted using the `hyp3.submit_autorift_job()` method.\n",
    "\n",
    "### Sentinel-1\n",
    "\n",
    "Sentinel-1 jobs are submitted using the [ESA granule ID](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/naming-conventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_pairs = [\n",
    "    ('S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07',\n",
    "     'S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654'),\n",
    "    ('S1B_IW_SLC__1SDH_20180821T204618_20180821T204645_012366_016CC2_59A7',\n",
    "     'S1B_IW_SLC__1SDH_20180809T204617_20180809T204644_012191_01674F_9345'),\n",
    "    ('S1A_IW_SLC__1SSH_20151214T080202_20151214T080229_009035_00CF68_780C',\n",
    "     'S1A_IW_SLC__1SSH_20151120T080202_20151120T080229_008685_00C5A7_105E'),\n",
    "    ('S1A_IW_SLC__1SSH_20150909T162413_20150909T162443_007640_00A97D_922B',\n",
    "     'S1A_IW_SLC__1SSH_20150828T162412_20150828T162431_007465_00A4AF_DC3E'),\n",
    "]\n",
    "\n",
    "s1_jobs = sdk.Batch()\n",
    "for g1, g2 in s1_pairs:\n",
    "    s1_jobs += hyp3.submit_autorift_job(g1, g2, name='s1-example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've given each job the name `s1-example`, which we can use later to search for these jobs.\n",
    "\n",
    "### Sentinel-2\n",
    "\n",
    "Seninel-2 jobs can be submitted using either the [ESA granule ID](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/naming-convention)\n",
    "or the [COG ID on AWS](https://registry.opendata.aws/sentinel-2-l2a-cogs/#:~:text=The%20Sentinel%2D2%20mission%20is,great%20use%20in%20ongoing%20studies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_pairs = [\n",
    "    # Can be either ESA granule IDs\n",
    "    ('S2B_MSIL2A_20201016T161349_N0214_R111_T07CDL_20201016T195625',\n",
    "     'S2B_MSIL2A_20201030T155329_N0214_R025_T07CDL_20201030T200159'),\n",
    "    # or AWS COG IDs\n",
    "    ('S2B_22WEB_20200903_0_L2A', 'S2B_22WEB_20200913_0_L2A'),\n",
    "]\n",
    "\n",
    "s2_jobs = sdk.Batch()\n",
    "for g1, g2 in s2_pairs:\n",
    "    s2_jobs += hyp3.submit_autorift_job(g1, g2, name='s2-example')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landsat 8\n",
    "\n",
    "**NOTE: Landsat support is coming soon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Currently unsupported\n",
    "l8_pairs = []\n",
    "\n",
    "l8_jobs = sdk.Batch()\n",
    "for g1, g2 in l8_pairs:\n",
    "    l8_jobs += hyp3.submit_autorift_job(g1, g2, name='l8-example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring jobs\n",
    "\n",
    "One jobs are submitted, you can either watch the jobs until they finish. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_jobs = hyp3.watch(s1_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will require you to keep the cell/terminal running. Or, you can come back later and search for jobs. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_jobs = hyp3.find_jobs(name='s1-example')\n",
    "s1_jobs = hyp3.watch(s1_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading files\n",
    "\n",
    "Batches are collections of jobs, and they provide a snapshot of the job status when the job was created or last\n",
    "refreshed. To get updated information on a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_jobs = hyp3.refresh(s1_jobs)\n",
    "s1_jobs.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyp3.watch()` will return a refreshed batch once the batch has completed.\n",
    "\n",
    "Batches can be added together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Jobs:\\n  S1:{len(s1_jobs)}\\n  S2:{len(s2_jobs)}\\n  L8:{len(l8_jobs)}')\n",
    "all_jobs = s1_jobs + s2_jobs + l8_jobs\n",
    "print(f'Total number of Jobs: {len(all_jobs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if every job was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs.succeeded()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and filter jobs by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succeeded_jobs = all_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "failed_jobs = all_jobs.filter_jobs(succeeded=False, running=False, failed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the files for all successful jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = succeeded_jobs.download_files('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: only succeeded jobs will have files to download.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
